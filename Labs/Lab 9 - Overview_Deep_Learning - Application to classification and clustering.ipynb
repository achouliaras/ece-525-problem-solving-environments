{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning: A Quick Overview\n",
    "\n",
    "\\begin{exercise}\n",
    "\n",
    "* Prepare an introductory presentation of NN concept\n",
    "* Implement a NN using sklearn library for binary classification  and clustering and compared it to the methods and datasets considered in Labs 8 and 9.\n",
    "\n",
    "\\end{exercise}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Artificial neural networks are computational systems that can learn to\n",
    "perform tasks by considering examples, generally without being\n",
    "programmed with any task-specific rules. It is supposed to mimic a\n",
    "biological system, wherein neurons interact by sending signals in the\n",
    "form of mathematical functions between layers. All layers can contain\n",
    "an arbitrary number of neurons, and each connection is represented by\n",
    "a weight variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall supervised learning setup\n",
    "\n",
    "- Input features $x^{(i)} \\in \\mathbb{R}^n$\n",
    "\n",
    "- Ouput $y^{(i)}$\n",
    "\n",
    "- Model parameters $\\theta \\in \\mathbb{R}^k$\n",
    "\n",
    "- Hypothesis function $h_{\\theta}: \\mathbb{R}^n \\rightarrow y$\n",
    "\n",
    "- Loss function $\\ell: y \\times y \\rightarrow \\mathbb{R}_+$\n",
    "\n",
    "\n",
    "- Machine learning optimization problem\n",
    "\n",
    "$$ \\min_{\\theta} \\sum_{i=1}^{m}\\ell\\left( h_{\\theta}\\left(x^{(i)}\\right),y^{(i)}\\right)$$\n",
    "\n",
    "$\\quad \\;$(possibly plus some additional regularization)\n",
    "\n",
    "\n",
    "We mainly considered the __linear__ hypothesis class\n",
    "\n",
    "$$h_{\\theta}\\left( x^{(i)}\\right) = \\theta^T \\phi (x^{(i)})$$\n",
    "\n",
    "for some set of _non-linear_ feature $\\phi: \\mathbb{R}^n \\rightarrow \\mathbb{R}^k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges with linear models\n",
    "\n",
    "- Linear models crucially depend on choosing \"good\" features\n",
    "\n",
    "\n",
    "- Some \"standard\" choices: polynomial features, radial basis functions, random features (suprisingly effective)\n",
    "\n",
    "\n",
    "- But, many specialized domains required highly engineered special features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial neurons\n",
    "\n",
    "The field of artificial neural networks has a long history of\n",
    "development, and is closely connected with the advancement of computer\n",
    "science and computers in general. A model of artificial neurons was\n",
    "first developed by McCulloch and Pitts in 1943 to study signal\n",
    "processing in the brain and has later been refined by others. The\n",
    "general idea is to mimic neural networks in the human brain, which is\n",
    "composed of billions of neurons that communicate with each other by\n",
    "sending electrical signals.  Each neuron accumulates its incoming\n",
    "signals, which must exceed an activation threshold to yield an\n",
    "output. If the threshold is not overcome, the neuron remains inactive,\n",
    "i.e. has zero output.\n",
    "\n",
    "This behaviour has inspired a simple mathematical model for an artificial neuron.\n",
    "\n",
    "$y = f(\\sum_{i=1}^n w_i x_i) = f(u)$\n",
    "\n",
    "Here, the output $y$ of the neuron is the value of its activation function, which have as input\n",
    "a weighted sum of signals $x_i, \\dots ,x_n$ received by $n$ other neurons.\n",
    "\n",
    "Conceptually, it is helpful to divide neural networks into four\n",
    "categories:\n",
    "1. general purpose neural networks for supervised learning,\n",
    "\n",
    "2. neural networks designed specifically for image processing, the most prominent example of this class being Convolutional Neural Networks (CNNs),\n",
    "\n",
    "3. neural networks for sequential data such as Recurrent Neural Networks (RNNs), and\n",
    "\n",
    "4. neural networks for unsupervised learning such as Deep Boltzmann Machines.\n",
    "\n",
    "In natural science, DNNs and CNNs have already found numerous\n",
    "applications. In statistical physics, they have been applied to detect\n",
    "phase transitions in 2D Ising and Potts models, lattice gauge\n",
    "theories, and different phases of polymers, or solving the\n",
    "Navier-Stokes equation in weather forecasting.  Deep learning has also\n",
    "found interesting applications in quantum physics. Various quantum\n",
    "phase transitions can be detected and studied using DNNs and CNNs,\n",
    "topological phases, and even non-equilibrium many-body\n",
    "localization. Representing quantum states as DNNs quantum state\n",
    "tomography are among some of the impressive achievements to reveal the\n",
    "potential of DNNs to facilitate the study of quantum systems.\n",
    "\n",
    "In quantum information theory, it has been shown that one can perform\n",
    "gate decompositions with the help of neural. \n",
    "\n",
    "The applications are not limited to the natural sciences. There is a\n",
    "plethora of applications in essentially all disciplines, from the\n",
    "humanities to life science and medicine.\n",
    "\n",
    "## Neural network types\n",
    "\n",
    "An artificial neural network (ANN), is a computational model that\n",
    "consists of layers of connected neurons, or nodes or units.  We will\n",
    "refer to these interchangeably as units or nodes, and sometimes as\n",
    "neurons.\n",
    "\n",
    "It is supposed to mimic a biological nervous system by letting each\n",
    "neuron interact with other neurons by sending signals in the form of\n",
    "mathematical functions between layers.  A wide variety of different\n",
    "ANNs have been developed, but most of them consist of an input layer,\n",
    "an output layer and eventual layers in-between, called *hidden\n",
    "layers*. All layers can contain an arbitrary number of nodes, and each\n",
    "connection between two nodes is associated with a weight variable.\n",
    "\n",
    "Neural networks (also called neural nets) are neural-inspired\n",
    "nonlinear models for supervised learning.  As we will see, neural nets\n",
    "can be viewed as natural, more powerful extensions of supervised\n",
    "learning methods such as linear and logistic regression and soft-max\n",
    "methods we discussed earlier.\n",
    "\n",
    "\n",
    "## Feed-forward neural networks\n",
    "\n",
    "The feed-forward neural network (FFNN) was the first and simplest type\n",
    "of ANNs that were devised. In this network, the information moves in\n",
    "only one direction: forward through the layers.\n",
    "\n",
    "Nodes are represented by circles, while the arrows display the\n",
    "connections between the nodes, including the direction of information\n",
    "flow. Additionally, each arrow corresponds to a weight variable\n",
    "(figure to come).  We observe that each node in a layer is connected\n",
    "to *all* nodes in the subsequent layer, making this a so-called\n",
    "*fully-connected* FFNN.\n",
    "\n",
    "\n",
    "\n",
    "## Convolutional Neural Network\n",
    "\n",
    "A different variant of FFNNs are *convolutional neural networks*\n",
    "(CNNs), which have a connectivity pattern inspired by the animal\n",
    "visual cortex. Individual neurons in the visual cortex only respond to\n",
    "stimuli from small sub-regions of the visual field, called a receptive\n",
    "field. This makes the neurons well-suited to exploit the strong\n",
    "spatially local correlation present in natural images. The response of\n",
    "each neuron can be approximated mathematically as a convolution\n",
    "operation.  (figure to come)\n",
    "\n",
    "Convolutional neural networks emulate the behaviour of neurons in the\n",
    "visual cortex by enforcing a *local* connectivity pattern between\n",
    "nodes of adjacent layers: Each node in a convolutional layer is\n",
    "connected only to a subset of the nodes in the previous layer, in\n",
    "contrast to the fully-connected FFNN.  Often, CNNs consist of several\n",
    "convolutional layers that learn local features of the input, with a\n",
    "fully-connected layer at the end, which gathers all the local data and\n",
    "produces the outputs. They have wide applications in image and video\n",
    "recognition.\n",
    "\n",
    "## Recurrent neural networks\n",
    "\n",
    "So far we have only mentioned ANNs where information flows in one\n",
    "direction: forward. *Recurrent neural networks* on the other hand,\n",
    "have connections between nodes that form directed *cycles*. This\n",
    "creates a form of internal memory which are able to capture\n",
    "information on what has been calculated before; the output is\n",
    "dependent on the previous computations. Recurrent NNs make use of\n",
    "sequential information by performing the same task for every element\n",
    "in a sequence, where each element depends on previous elements. An\n",
    "example of such information is sentences, making recurrent NNs\n",
    "especially well-suited for handwriting and speech recognition.\n",
    "\n",
    "## Other types of networks\n",
    "\n",
    "There are many other kinds of ANNs that have been developed. One type\n",
    "that is specifically designed for interpolation in multidimensional\n",
    "space is the radial basis function (RBF) network. RBFs are typically\n",
    "made up of three layers: an input layer, a hidden layer with\n",
    "non-linear radial symmetric activation functions and a linear output\n",
    "layer (''linear'' here means that each node in the output layer has a\n",
    "linear activation function). The layers are normally fully-connected\n",
    "and there are no cycles, thus RBFs can be viewed as a type of\n",
    "fully-connected FFNN. They are however usually treated as a separate\n",
    "type of NN due the unusual activation functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptrons\n",
    "\n",
    "One uses often so-called fully-connected feed-forward neural networks\n",
    "with three or more layers (an input layer, one or more hidden layers\n",
    "and an output layer) consisting of neurons that have non-linear\n",
    "activation functions.\n",
    "\n",
    "Such networks are often called *multilayer perceptrons* (MLPs).\n",
    "\n",
    "<img src=\"neural-networks/multiple-output-nn.png\" width = 300>\n",
    "\n",
    "## Why multilayer perceptrons?\n",
    "\n",
    "According to the *Universal approximation theorem*, a feed-forward\n",
    "neural network with just a single hidden layer containing a finite\n",
    "number of neurons can approximate a continuous multidimensional\n",
    "function to arbitrary accuracy, assuming the activation function for\n",
    "the hidden layer is a **non-constant, bounded and\n",
    "monotonically-increasing continuous function**.\n",
    "\n",
    "Note that the requirements on the activation function only applies to\n",
    "the hidden layer, the output nodes are always assumed to be linear, so\n",
    "as to not restrict the range of output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Approximation Theorems\n",
    "\n",
    "Leshno and Schocken (1991) showed:\n",
    "\n",
    "– A neural network with one [possibly huge] hidden layer can uniformly approximate any continuous function on a compact set iff the activation function is not a polynomial (i.e. tanh, logistic, and ReLU all work, as do $\\sin$,$\\cos$, $\\exp$, etc.). \n",
    "\n",
    "• In more words:\n",
    "\n",
    "– Let $\\varphi(\\cdot)$ be any non-polynomial function (an activation function).Let K be any compact set in $\\mathbb R^{m}$. (Such as the unit hypercube $[0,1]^{m}$.)\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "– Let $f:K\\to\\mathbb R$ be any continuous function on a compact set $K\\subset\\mathbb R^{m}$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "– Then $\\forall\\epsilon>0$, there exists an integer N (the number of hidden units), and parameters $v_{i},b_{i}\\in\\mathbb R$ and $w_{i}\\in\\mathbb R^{m}$ such that the function $F(x)=\\sum_{i=1}^{N}v_{i}\\varphi(w_{i}^{T}x+b_{i})$ satisfies $\\left|F(x)-f(x)\\right|<\\epsilon$ for all $x\\in K$. \n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Leshno & Schocken note that this doesn't work without the bias $term b_{i}$ (they call it the threshold term). (e.g. consider $\\varphi=\\sin$: then we always have $F(-x)=-F(x))$ Hornik et al and concurrently by Cybenko in 1989 showed we get uniform approximation for activation functions that are nonconstant, bounded, nondecreasing, and continuous. These functions are known as squashing functions.). http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&rep=rep1&type=pdf Leshno: https://archive.nyu.edu/bitstream/2451/14384/1/IS-91-26.pdf points out that the bias term (they call the threshold) is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Approximation Ability: $f(x)=x^{2}$\n",
    "\n",
    "• 3 hidden units; tanh activation functions \n",
    "\n",
    "• Blue dots are training points; Dashed lines are hidden unit outputs; Final output in Red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"Figures/neural-networks/Figure5.3a.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20fcc956da0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"Figures/neural-networks/Figure5.3a.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical model\n",
    "\n",
    "The output $y$ is produced via the activation function $f$\n",
    "\n",
    "$$y = f(\\sum_{i=1}^n w_i x_i) = f(u)$$\n",
    "\n",
    "This function receives $x_i$ as inputs.\n",
    "\n",
    "Generates the weighted sum from all previews neurons  $z=(\\sum_{i=1}^n w_ix_i+b_i)$. \n",
    "\n",
    "In an FFNN of such neurons, the *inputs* $x_i$ are the *outputs* of\n",
    "the neurons in the preceding layer. Furthermore, an MLP is\n",
    "fully-connected, which means that each neuron receives a weighted sum\n",
    "of the outputs of *all* neurons in the previous layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, for each node $i$ in the first hidden layer, we calculate a weighted sum $z_i^1$ of the input coordinates $x_j$,\n",
    "\n",
    "\\begin{equation} z_i^1 = \\sum_{j=1}^{M} w_{ij}^1 x_j + b_i^1\n",
    "\\label{_auto1} \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Here $b_i$ is the so-called bias which is normally needed in\n",
    "case of zero activation weights or inputs. How to fix the biases and\n",
    "the weights will be discussed below.  The value of $z_i^1$ is the\n",
    "argument to the activation function $f_i$ of each node $i$, The\n",
    "variable $M$ stands for all possible inputs to a given node $i$ in the\n",
    "first layer.  We define  the output $y_i^1$ of all neurons in layer 1 as\n",
    "\n",
    "\\begin{equation}\n",
    " y_i^1 = f(z_i^1) = f\\left(\\sum_{j=1}^M w_{ij}^1 x_j  + b_i^1\\right)\n",
    "\\label{outputLayer1} \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "where we assume that all nodes in the same layer have identical\n",
    "activation functions, hence the notation $f$. In general, we could assume in the more general case that different layers have different activation functions.\n",
    "In this case we would identify these functions with a superscript $l$ for the $l$-th layer,\n",
    "\n",
    "\\begin{equation}\n",
    " y_i^l = f^l(u_i^l) = f^l\\left(\\sum_{j=1}^{N_{l-1}} w_{ij}^l y_j^{l-1} + b_i^l\\right)\n",
    "\\label{generalLayer} \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "where $N_l$ is the number of nodes in layer $l$. When the output of\n",
    "all the nodes in the first hidden layer are computed, the values of\n",
    "the subsequent layer can be calculated and so forth until the output\n",
    "is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical model\n",
    "\n",
    "The output of neuron $i$ in layer 2 is thus,\n",
    "\n",
    "\\begin{equation}\n",
    " y_i^2 = f^2\\left(\\sum_{j=1}^N w_{ij}^2 y_j^1 + b_i^2\\right) \n",
    "\\label{_auto2} \\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation} \n",
    " = f^2\\left[\\sum_{j=1}^N w_{ij}^2f^1\\left(\\sum_{k=1}^M w_{jk}^1 x_k + b_j^1\\right) + b_i^2\\right]\n",
    "\\label{outputLayer2} \\tag{6}\n",
    "\\end{equation}\n",
    "\n",
    "where we have substituted $y_k^1$ with the inputs $x_k$. Finally, the ANN output reads\n",
    "\n",
    "\\begin{equation}\n",
    " y_i^3 = f^3\\left(\\sum_{j=1}^N w_{ij}^3 y_j^2 + b_i^3\\right) \n",
    "\\label{_auto3} \\tag{7}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation} \n",
    " = f_3\\left[\\sum_{j} w_{ij}^3 f^2\\left(\\sum_{k} w_{jk}^2 f^1\\left(\\sum_{m} w_{km}^1 x_m + b_k^1\\right) + b_j^2\\right)\n",
    "  + b_1^3\\right]\n",
    "\\label{_auto4} \\tag{8}\n",
    "\\end{equation}\n",
    "\n",
    "We can generalize this expression to an MLP with $l$ hidden\n",
    "layers. The complete functional form is,\n",
    "\n",
    "\\begin{equation}\n",
    "y^{l+1}_i = f^{l+1}\\left[\\!\\sum_{j=1}^{N_l} w_{ij}^3 f^l\\left(\\sum_{k=1}^{N_{l-1}}w_{jk}^{l-1}\\left(\\dots f^1\\left(\\sum_{n=1}^{N_0} w_{mn}^1 x_n+ b_m^1\\right)\\dots\\right)+b_k^2\\right)+b_1^3\\right] \n",
    "\\label{completeNN} \\tag{9}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "which illustrates a basic property of MLPs: The only independent\n",
    "variables are the input values $x_n$.\n",
    "\n",
    "## Mathematical model\n",
    "\n",
    "This confirms that an MLP, despite its quite convoluted mathematical\n",
    "form, is nothing more than an analytic function, specifically a\n",
    "mapping of real-valued vectors $\\hat{x} \\in \\mathbb{R}^n \\rightarrow\n",
    "\\hat{y} \\in \\mathbb{R}^m$.\n",
    "\n",
    "Furthermore, the flexibility and universality of an MLP can be\n",
    "illustrated by realizing that the expression is essentially a nested\n",
    "sum of scaled activation functions of the form\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    " f(x) = c_1 f(c_2 x + c_3) + c_4\n",
    "\\label{_auto5} \\tag{10}\n",
    "\\end{equation}\n",
    "\n",
    "where the parameters $c_i$ are weights and biases. By adjusting these\n",
    "parameters, the activation functions can be shifted up and down or\n",
    "left and right, change slope or be rescaled which is the key to the\n",
    "flexibility of a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix-vector notation\n",
    "\n",
    "We can introduce a more convenient notation for the activations in an A NN. \n",
    "\n",
    "Additionally, we can represent the biases and activations\n",
    "as layer-wise column vectors $\\hat{b}_l$ and $\\hat{y}_l$, so that the $i$-th element of each vector \n",
    "is the bias $b_i^l$ and activation $y_i^l$ of node $i$ in layer $l$ respectively. \n",
    "\n",
    "We have that $\\mathrm{W}_l$ is an $N_{l-1} \\times N_l$ matrix, while $\\hat{b}_l$ and $\\hat{y}_l$ are $N_l \\times 1$ column vectors. \n",
    "With this notation, the sum becomes a matrix-vector multiplication, and we can write\n",
    "the equation for the activations of hidden layer 2 (assuming three nodes for simplicity) as\n",
    "\n",
    "\\begin{equation}\n",
    " \\hat{y}_2 = f_2(\\mathrm{W}_2 \\hat{y}_{1} + \\hat{b}_{2}) = \n",
    " f_2\\left(\\left[\\begin{array}{ccc}\n",
    "    w^2_{11} &w^2_{12} &w^2_{13} \\\\\n",
    "    w^2_{21} &w^2_{22} &w^2_{23} \\\\\n",
    "    w^2_{31} &w^2_{32} &w^2_{33} \\\\\n",
    "    \\end{array} \\right] \\cdot\n",
    "    \\left[\\begin{array}{c}\n",
    "           y^1_1 \\\\\n",
    "           y^1_2 \\\\\n",
    "           y^1_3 \\\\\n",
    "          \\end{array}\\right] + \n",
    "    \\left[\\begin{array}{c}\n",
    "           b^2_1 \\\\\n",
    "           b^2_2 \\\\\n",
    "           b^2_3 \\\\\n",
    "          \\end{array}\\right]\\right).\n",
    "\\label{_auto6} \\tag{11}\n",
    "\\end{equation}\n",
    "\n",
    "### Matrix-vector notation  and activation\n",
    "\n",
    "The activation of node $i$ in layer 2 is\n",
    "\n",
    "\\begin{equation}\n",
    " y^2_i = f_2\\Bigr(w^2_{i1}y^1_1 + w^2_{i2}y^1_2 + w^2_{i3}y^1_3 + b^2_i\\Bigr) = \n",
    " f_2\\left(\\sum_{j=1}^3 w^2_{ij} y_j^1 + b^2_i\\right).\n",
    "\\label{_auto7} \\tag{12}\n",
    "\\end{equation}\n",
    "\n",
    "This is not just a convenient and compact notation, but also a useful\n",
    "and intuitive way to think about MLPs: The output is calculated by a\n",
    "series of matrix-vector multiplications and vector additions that are\n",
    "used as input to the activation functions. For each operation\n",
    "$\\mathrm{W}_l \\hat{y}_{l-1}$ we move forward one layer.\n",
    "\n",
    "\n",
    "### Activation functions\n",
    "\n",
    "A property that characterizes a neural network, other than its\n",
    "connectivity, is the choice of activation function(s).  As described\n",
    "in, the following restrictions are imposed on an activation function\n",
    "for a FFNN to fulfill the universal approximation theorem\n",
    "\n",
    "  * Non-constant\n",
    "\n",
    "  * Bounded\n",
    "\n",
    "  * Monotonically-increasing\n",
    "\n",
    "  * Continuous\n",
    "\n",
    "### Activation functions, Logistic and Hyperbolic ones\n",
    "\n",
    "The second requirement excludes all linear functions. Furthermore, in\n",
    "a MLP with only linear activation functions, each layer simply\n",
    "performs a linear transformation of its inputs.\n",
    "\n",
    "Regardless of the number of layers, the output of the NN will be\n",
    "nothing but a linear function of the inputs. Thus we need to introduce\n",
    "some kind of non-linearity to the NN to be able to fit non-linear\n",
    "functions Typical examples are the logistic *Sigmoid*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGqlJREFUeJzt3X2QZXV95/H3h+FBIyogYUQYHhTWEp8wdMAt3dig4GhcSO1qhN0obCRTpsTEZN2IcUstEhM02cXNqquzSgUfwviwPkxSE5EIvW7iE4MiAgqMSGQcDBHwoaOCQ3/3j3t6+p6me6Zn7pm+fS/vV9Wtvuec37nnO7/q6c89T7+TqkKSpFn7DLsASdLKYjBIkloMBklSi8EgSWoxGCRJLQaDJKnFYJB2Q5InJvlqkh8n+Z1l3O5RSaaTrFqubeqhy2DQWEny5iQf3Iub+ANgqqoeWVV/sbc2kuT2JM+bna6q71TVgVX1wN7apjTLYJB2z9HAjcMuQtqbDAaNpCSvS/Ld5pDOzUmem2Qt8IfAS5vDLl9r2j46yfuS3Nms88ezh2SSnJfkH5L8zyQ/TPLNJM9dZJtXAacC72g+/18lmUpyfl+b85L8fd90JXllkluT3JvknUnSt/y3knyj+XfclOSXknwAOAr462Y7f5DkmOaz9m3We1ySjUnuSbIlyW/1feabk3wkyfubz70xyUSX/a/xZjBo5CR5InAB8MtV9Ujg+cDtVfVp4E+ADzeHXZ7erHIZsB04DngGcAZwft9HngLcBhwKvAn4eJJD5m+3qk4D/h9wQfP5tyyx5BcBvww8Hfj1pl6SvAR4M/By4FHAmcDdVfUy4DvAv22287YFPvNyYCvwOODFwJ/MC7QzgQ3AQcBG4B1LrFUyGDSSHgAOAE5Isl9V3V5V31qoYZLVwAuA11TVv1TVXcAlwNl9ze4C3l5VP6+qDwM3A7/aYb0XV9UPquo7wNXAic3884G3VdU11bOlqv5xVx+WZA3wbOB1VfWzqroOeC/wsr5mf19Vm5pzEh+gF0rSkhgMGjlVtQV4Db1v23cl2ZDkcYs0PxrYD7gzyQ+S/AB4D3BYX5vvVns0yX+k9028K9/re/8T4MDm/RpgwUDbhccB91TVj/vm/SNwxE62+bDZw1DSrhgMGklV9VdV9Wx6f/gLeOvsonlN7wDuAw6tqoOa16Oq6sl9bY7oP+5P7/j+tiWW8i/AL/RNP3bJ/4hebU9YZNnOhj3eBhyS5JF9844Cvrsb25YWZTBo5DT3EpyW5ADgZ8BP6R1eAvgn4Jgk+wBU1Z3AZ4D/luRRSfZJ8oQkz+n7yMOA30myX3Pc/0nApiWWcx3w75L8QpLjgFfsxj/lvcBrk5yUnuOSHN3373j8QitV1R3A54E/TfKwJE9rtvuh3di2tCiDQaPoAOBi4Pv0DpkcRu9qJICPNj/vTvKV5v3Lgf2Bm4B7gY8Bh/d93peA45vPewvw4qq6e4m1XALcT+8P+WXsxh/nqvpos72/An4MfBKYPen9p8B/bQ5/vXaB1c8BjqG39/AJ4E1VdeVSty3tTHxQjx7KkpwHnN8clpKEewySpHk6CYYklya5K8kNiyyfbG4euq55vbFv2drmBqUtSS7soh5J0p7r5FBSkl8BpoH3V9VTFlg+Cby2ql40b/4q4BbgdHo361wDnFNVNw1clCRpj3Syx1BVnwPu2YNVTwa2VNVtVXU/vTs1z+qiJknSnlnOG17+dTN2zTZ6ew830rsh546+NlvpDU/wIEnWAesAHv7wh5+0Zs2avVzuzs3MzLDPPp6iAfuin30xx76Ys1L64pZbbvl+Vf3irtotVzB8BTi6qqaTvJDeZXnHA1mg7YLHtqpqPbAeYGJiojZv3ry3al2SqakpJicnh1rDSmFfzLEv5tgXc1ZKXyTZ5ZArsExXJVXVj6pqunm/CdgvyaH09hD6v/ofydLvOJUk7QXLEgxJHjs75ECSk5vt3k3vZPPxSY5Nsj+9gc02LkdNkqSFdXIoKcnlwCRwaJKt9IYu3g+gqt5Nb1jg306ynd7wBWc3g5ZtT3IBcAWwCri0OfcgSRqSToKhqs7ZxfJ3sMh48M2hpaWOSyNJ2suGf5pckrSiGAySpBaDQZLUYjBIkloMBklSi8EgSWoxGCRJLQaDJKnFYJAktRgMkqQWg0GS1GIwSJJaDAZJUovBIElqMRgkSS0GgySpxWCQJLUYDJKklk6CIcmlSe5KcsMiy/9jkuub1+eTPL1v2e1Jvp7kuiSbu6hHkrTnutpj+Etg7U6Wfxt4TlU9DfgjYP285adW1YlVNdFRPZKkPbRvFx9SVZ9LcsxOln++b/KLwJFdbFeS1L1hnGN4BfC3fdMFfCbJtUnWDaEeSVKfVFU3H9TbY/ibqnrKTtqcCrwLeHZV3d3Me1xVbUtyGHAl8Oqq+twC664D1gGsXr36pA0bNnRS956anp7mwAMPHGoNK4V9Mce+mGNfzFkpfXHqqadeu5RD9p0cSlqKJE8D3gu8YDYUAKpqW/PzriSfAE4GHhQMVbWe5tzExMRETU5OLkfZi5qammLYNawU9sUc+2KOfTFn1PpiWQ4lJTkK+Djwsqq6pW/+I5I8cvY9cAaw4JVNkqTl0ckeQ5LLgUng0CRbgTcB+wFU1buBNwKPAd6VBGB7szuzGvhEM29f4K+q6tNd1CRJ2jNdXZV0zi6Wnw+cv8D824CnP3gNSdKweOezJKnFYJAktRgMkqQWg0GS1GIwSJJaDAZJUovBIElqMRgkSS0GgySpxWCQJLUYDJKkFoNBktRiMEiSWgwGSVKLwSBJajEYJEktBoMkqcVgkCS1GAySpJZOgiHJpUnuSnLDIsuT5C+SbElyfZJf6lt2bpJbm9e5XdQjSdpz+3b0OX8JvAN4/yLLXwAc37xOAf4XcEqSQ4A3ARNAAdcm2VhV93ZUl7SsZqr42c8fGHYZK8L9D9gXs1ZCX+yTLLltJ8FQVZ9LcsxOmpwFvL+qCvhikoOSHA5MAldW1T0ASa4E1gKXd1GXtNwuufY+fvOKTw+7jJXjSvtihyH3xalP/MUlt+1qj2FXjgDu6Jve2sxbbP6DJFkHrANYvXo1U1NTe6XQpZqenh56DSuFfTHnzuntHPXIVZx8+KphlzJ09993P/sfsP+wy1gRVkJfHPbwHy257XIFw0L7MLWT+Q+eWbUeWA8wMTFRk5OTnRW3J6amphh2DSuFfdHn/25i4rjD+fOXnjjsSobO34s5K6UvXnfO0tot11VJW4E1fdNHAtt2Ml8aSbXY1x1phCxXMGwEXt5cnfRM4IdVdSdwBXBGkoOTHAyc0cyTRlKxeyf5pJWok0NJSS6ndyL50CRb6V1ptB9AVb0b2AS8ENgC/AT4T82ye5L8EXBN81EXzZ6IlkbVPuaCRlxXVyXt9MhVczXSqxZZdilwaRd1SMM2UxCPJWnEeeez1LF9/F+lEeevsNShmQLPPmvUGQxSh4ryHINGnsEgdam8Kkmjz2CQOjQDmAsadQaD1DH3GDTqDAapQzMLDugijRaDQeqYewwadQaD1KEqzzFo9BkMUodmcEgMjT6DQeqSl6tqDBgMUodmwBufNfIMBqlL7jFoDBgMUod8To/GgcEgdcgH9WgcGAxSh7xcVePAYJA6VEBMBo04g0HqSO9Bhd7HoNHXSTAkWZvk5iRbkly4wPJLklzXvG5J8oO+ZQ/0LdvYRT3SMMyOk+SjPTXqBn7mc5JVwDuB04GtwDVJNlbVTbNtqur3+tq/GnhG30f8tKpOHLQOadjcY9C46GKP4WRgS1XdVlX3AxuAs3bS/hzg8g62K60oO/YYDAaNuIH3GIAjgDv6prcCpyzUMMnRwLHAVX2zH5ZkM7AduLiqPrnIuuuAdQCrV69mampq8MoHMD09PfQaVgr7oufnTTLc/u1vMzX13SFXM3z+XswZtb7oIhgW+n602Kj0ZwMfq6oH+uYdVVXbkjweuCrJ16vqWw/6wKr1wHqAiYmJmpycHLDswUxNTTHsGlYK+6LnZz9/AD7zaR7/hMczOXncsMsZOn8v5oxaX3RxKGkrsKZv+khg2yJtz2beYaSq2tb8vA2Yon3+QRoZMzvOMXgsSaOti2C4Bjg+ybFJ9qf3x/9BVxcleSJwMPCFvnkHJzmgeX8o8CzgpvnrSqOgyQVPPmvkDXwoqaq2J7kAuAJYBVxaVTcmuQjYXFWzIXEOsKFmL93oeRLwniQz9ELq4v6rmaRRMrvH4OWqGnVdnGOgqjYBm+bNe+O86TcvsN7ngad2UYM0bLPfeDySpFHnnc9SR2qm99MhMTTqDAapI4U3uGk8GAxSR+aGxJBGm8EgdWTH5aruMmjEGQxSR2rHkBgGg0abwSB1pHZcriqNNoNB6sjs5are+axRZzBIHdlxg5u5oBFnMEgdcUgMjQuDQeqIQ2JoXBgMUkfKB/VoTBgMUkfmDiWZDBptBoPUEU8+a1wYDFJHvFxV48JgkDriHoPGhcEgdWTHnc8mg0acwSB1pBxdVWPCYJA6MuNVSRoTnQRDkrVJbk6yJcmFCyw/L8k/J7mueZ3ft+zcJLc2r3O7qEcaBh/Uo3Ex8DOfk6wC3gmcDmwFrkmysapumtf0w1V1wbx1DwHeBEzQu6jj2mbdewetS1puMzse7TncOqRBdbHHcDKwpapuq6r7gQ3AWUtc9/nAlVV1TxMGVwJrO6hJWnazewyefNaoG3iPATgCuKNveitwygLt/n2SXwFuAX6vqu5YZN0jFtpIknXAOoDVq1czNTU1eOUDmJ6eHnoNK4V90XP7Dx8A4MYbbuCAf/7mkKsZPn8v5oxaX3QRDAt9Pap5038NXF5V9yV5JXAZcNoS1+3NrFoPrAeYmJioycnJPS64C1NTUwy7hpXCvui5fusP4Av/wNOe+lQmT1g97HKGzt+LOaPWF10cStoKrOmbPhLY1t+gqu6uqvuayf8NnLTUdaVRsWOsJK/104jr4lf4GuD4JMcm2R84G9jY3yDJ4X2TZwLfaN5fAZyR5OAkBwNnNPOkkeOw2xoXAx9KqqrtSS6g9wd9FXBpVd2Y5CJgc1VtBH4nyZnAduAe4Lxm3XuS/BG9cAG4qKruGbQmaRhmj4F67lmjrotzDFTVJmDTvHlv7Hv/euD1i6x7KXBpF3VIw+SQGBoXHg2VOuKjPTUuDAapIzM7xkoyGTTaDAapI7Mnn91j0KgzGKSOzD3z2WTQaDMYpI6UD+rRmDAYpI74aE+NC4NB6oiP9tS4MBikjni5qsaFwSB1ZHaPwYd7atQZDFJH3GPQuDAYpI7MPdrTZNBoMxikjvhoT40Lg0HqiJeralwYDFJH5k4+S6PNYJA6Mnfy2T0GjTaDQeqIQ2JoXBgMUkdm3GPQmDAYpI7MXa465EKkAXUSDEnWJrk5yZYkFy6w/PeT3JTk+iSfTXJ037IHklzXvDZ2UY80DDse1GMwaMQN/MznJKuAdwKnA1uBa5JsrKqb+pp9FZioqp8k+W3gbcBLm2U/raoTB61DGjaf+axx0cUew8nAlqq6raruBzYAZ/U3qKqrq+onzeQXgSM72K60oux4UM9wy5AGNvAeA3AEcEff9FbglJ20fwXwt33TD0uyGdgOXFxVn1xopSTrgHUAq1evZmpqapCaBzY9PT30GlYK+6Lnpm3bAbjmy1/mO4/w9J2/F3NGrS+6CIaFviAteKdPkt8AJoDn9M0+qqq2JXk8cFWSr1fVtx70gVXrgfUAExMTNTk5OXDhg5iammLYNawU9kXP3dduheu/xjOfeQpHP+YRwy5n6Py9mDNqfdHF15qtwJq+6SOBbfMbJXke8AbgzKq6b3Z+VW1rft4GTAHP6KAmadnN3vns5aoadV0EwzXA8UmOTbI/cDbQurooyTOA99ALhbv65h+c5IDm/aHAs4D+k9bSyNjxNAZzQSNu4ENJVbU9yQXAFcAq4NKqujHJRcDmqtoI/BlwIPDR5oqN71TVmcCTgPckmaEXUhfPu5pJGhlelaRx0cU5BqpqE7Bp3rw39r1/3iLrfR54ahc1SMPmg3o0Lrx0QurIjhvcvGBVI85gkDrikBgaFwaD1JGZHWefh1qGNDCDQepIebmqxoTBIHXEB/VoXBgMUkdmb3AzFjTqDAapI+4xaFwYDFJHZhxeVWPCYJA64g1uGhcGg9SR2fsYHBJDo85gkDoy4x6DxoTBIHXEk88aFwaD1JEdJ5+lEWcwSB1zj0GjzmCQOjIzM3vyeciFSAMyGKSOzHiOQWPCYJA64rDbGhcGg9SRHQ/qcY9BI66TYEiyNsnNSbYkuXCB5Qck+XCz/EtJjulb9vpm/s1Jnt9FPdJQVDkahsbCwMGQZBXwTuAFwAnAOUlOmNfsFcC9VXUccAnw1mbdE4CzgScDa4F3NZ8njZwZr1bVmNi3g884GdhSVbcBJNkAnAXc1NfmLODNzfuPAe9Ib3/7LGBDVd0HfDvJlubzvrCzDf7opz/nMzd+r4PS99wN/7Sd+4dcw0phX/Tc9v1pzy9oLHQRDEcAd/RNbwVOWaxNVW1P8kPgMc38L85b94iFNpJkHbAOYP/HHse6D1zbQekD+uoKqGGlsC8AOHC/YmpqathlrAjT09P2RWPU+qKLYFjoO9L8nerF2ixl3d7MqvXAeoAnP/0Z9eFXP3t3auzctddu5qSTJoZaw0phX8z51g1fYXJycthlrAhTU1P2RWPU+qKLYNgKrOmbPhLYtkibrUn2BR4N3LPEdR/k4fut4ilHPHqQmgf2/VuHX8NKYV/M+f6tHkvS6OviqqRrgOOTHJtkf3onkzfOa7MROLd5/2Lgquo9OX0jcHZz1dKxwPHAlzuoSZK0hwbeY2jOGVwAXAGsAi6tqhuTXARsrqqNwPuADzQnl++hFx407T5C70T1duBVVfXAoDVJkvZcF4eSqKpNwKZ5897Y9/5nwEsWWfctwFu6qEOSNDjvfJYktRgMkqQWg0GS1GIwSJJaDAZJUovBIElqMRgkSS0GgySpxWCQJLUYDJKkFoNBktRiMEiSWgwGSVKLwSBJajEYJEktBoMkqcVgkCS1GAySpJaBgiHJIUmuTHJr8/PgBdqcmOQLSW5Mcn2Sl/Yt+8sk305yXfM6cZB6JEmDG3SP4ULgs1V1PPDZZnq+nwAvr6onA2uBtyc5qG/5f6mqE5vXdQPWI0ka0KDBcBZwWfP+MuDX5jeoqluq6tbm/TbgLuAXB9yuJGkvGTQYVlfVnQDNz8N21jjJycD+wLf6Zr+lOcR0SZIDBqxHkjSgVNXOGyR/Bzx2gUVvAC6rqoP62t5bVQ86z9AsOxyYAs6tqi/2zfsevbBYD3yrqi5aZP11wDqA1atXn7Rhw4ad/8v2sunpaQ488MCh1rBS2Bdz7Is59sWcldIXp5566rVVNbHLhlW1xy/gZuDw5v3hwM2LtHsU8BXgJTv5rEngb5ay3ZNOOqmG7eqrrx52CSuGfTHHvphjX8xZKX0BbK4l/I0d9FDSRuDc5v25wKfmN0iyP/AJ4P1V9dF5yw5vfobe+YkbBqxHkjSgQYPhYuD0JLcCpzfTJJlI8t6mza8DvwKct8BlqR9K8nXg68ChwB8PWI8kaUD7DrJyVd0NPHeB+ZuB85v3HwQ+uMj6pw2yfUlS97zzWZLUYjBIkloMBklSi8EgSWoxGCRJLQaDJKnFYJAktRgMkqQWg0GS1GIwSJJaDAZJUovBIElqMRgkSS0GgySpxWCQJLUYDJKkFoNBktRiMEiSWgwGSVLLQMGQ5JAkVya5tfl58CLtHkhyXfPa2Df/2CRfatb/cJL9B6lHkjS4QfcYLgQ+W1XHA59tphfy06o6sXmd2Tf/rcAlzfr3Aq8YsB5J0oAGDYazgMua95cBv7bUFZMEOA342J6sL0naO/YdcP3VVXUnQFXdmeSwRdo9LMlmYDtwcVV9EngM8IOq2t602QocsdiGkqwD1jWT00luHrD2QR0KfH/INawU9sUc+2KOfTFnpfTF0UtptMtgSPJ3wGMXWPSG3SjmqKraluTxwFVJvg78aIF2tdgHVNV6YP1ubHOvSrK5qiaGXcdKYF/MsS/m2BdzRq0vdhkMVfW8xZYl+ackhzd7C4cDdy3yGduan7clmQKeAfwf4KAk+zZ7DUcC2/bg3yBJ6tCg5xg2Auc2788FPjW/QZKDkxzQvD8UeBZwU1UVcDXw4p2tL0laXoMGw8XA6UluBU5vpkkykeS9TZsnAZuTfI1eEFxcVTc1y14H/H6SLfTOObxvwHqW04o5rLUC2Bdz7Is59sWckeqL9L64S5LU453PkqQWg0GS1GIwdCDJa5NUc3L9ISnJnyX5ZpLrk3wiyUHDrmm5JVmb5OYkW5IsNgrA2EuyJsnVSb6R5MYkvzvsmoYpyaokX03yN8OuZakMhgElWUPvxPt3hl3LkF0JPKWqngbcArx+yPUsqySrgHcCLwBOAM5JcsJwqxqa7cB/rqonAc8EXvUQ7guA3wW+MewidofBMLhLgD9gJzfnPRRU1Wf67mL/Ir37Uh5KTga2VNVtVXU/sIHekDEPOVV1Z1V9pXn/Y3p/FBcd1WCcJTkS+FXgvbtqu5IYDANIcibw3ar62rBrWWF+E/jbYRexzI4A7uib3ukQLw8VSY6hd0Prl4ZbydC8nd4Xx5lhF7I7Bh0raeztYkiQPwTOWN6KhmdnfVFVn2ravIHeoYQPLWdtK0AWmPeQ3otMciC9EQ5eU1ULDYEz1pK8CLirqq5NMjnsenaHwbALiw0JkuSpwLHA13oDxXIk8JUkJ1fV95axxGWzs+FRAJKcC7wIeG499G6Q2Qqs6Zt+SA/xkmQ/eqHwoar6+LDrGZJnAWcmeSHwMOBRST5YVb8x5Lp2yRvcOpLkdmCiqlbCCIrLLsla4L8Dz6mqfx52Pcstyb70Tro/F/gucA3wH6rqxqEWNgTNkPqXAfdU1WuGXc9K0OwxvLaqXjTsWpbCcwzqyjuARwJXNk/qe/ewC1pOzYn3C4Ar6J1s/chDMRQazwJeBpzW9+TGFw67KC2dewySpBb3GCRJLQaDJKnFYJAktRgMkqQWg0GS1GIwSJJaDAZJUovBIHUgySv7bub6dpKrh12TtKe8wU3qUDNG0FXA26rqr4ddj7Qn3GOQuvU/gKsMBY0yR1eVOpLkPOBoemMmSSPLQ0lSB5KcRG9E0X9TVfcOux5pEB5KkrpxAXAIcHVzAnqkHuUo9XOPQZLU4h6DJKnFYJAktRgMkqQWg0GS1GIwSJJaDAZJUovBIElq+f94nzFbiiaG4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\"\"\"The sigmoid function (or the logistic curve) is a \n",
    "function that takes any real number, z, and outputs a number (0,1).\n",
    "It is useful in neural networks for assigning weights on a relative scale.\n",
    "The value z is the weighted sum of parameters involved in the learning algorithm.\"\"\"\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mt\n",
    "\n",
    "z = numpy.arange(-5, 5, .1)\n",
    "sigma_fn = numpy.vectorize(lambda z: 1/(1+numpy.exp(-z)))\n",
    "sigma = sigma_fn(z)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(z, sigma)\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "ax.set_xlim([-5,5])\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('z')\n",
    "ax.set_title('sigmoid function')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Step Function\"\"\"\n",
    "z = numpy.arange(-5, 5, .02)\n",
    "step_fn = numpy.vectorize(lambda z: 1.0 if z >= 0.0 else 0.0)\n",
    "step = step_fn(z)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(z, step)\n",
    "ax.set_ylim([-0.5, 1.5])\n",
    "ax.set_xlim([-5,5])\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('z')\n",
    "ax.set_title('step function')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Sine Function\"\"\"\n",
    "z = numpy.arange(-2*mt.pi, 2*mt.pi, 0.1)\n",
    "t = numpy.sin(z)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(z, t)\n",
    "ax.set_ylim([-1.0, 1.0])\n",
    "ax.set_xlim([-2*mt.pi,2*mt.pi])\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('z')\n",
    "ax.set_title('sine function')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Plots a graph of the squashing function used by a rectified linear\n",
    "unit\"\"\"\n",
    "z = numpy.arange(-2, 2, .1)\n",
    "zero = numpy.zeros(len(z))\n",
    "y = numpy.max([zero, z], axis=0)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(z, y)\n",
    "ax.set_ylim([-2.0, 2.0])\n",
    "ax.set_xlim([-2.0, 2.0])\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('z')\n",
    "ax.set_title('Rectified linear unit')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation Properties of Multilayer Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Multinomial Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: Multinomial Logistic Regression\n",
    "\n",
    "• Setting: $\\mathcal X=\\mathbb R^{d}, \\mathcal Y=\\left\\{ 1,\\ldots,k\\right\\} $\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• For each x, we want to produce a distribution on k classes.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Such a distribution is called a “multinoulli” or “categorical” distribution.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Represent categorical distribution by probability vector $\\theta=\\left(\\theta_{1},\\ldots,\\theta_{k}\\right)\\in\\mathbb R^{k}$, where\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    " -  $\\sum_{y=1}^{k}\\theta_{y}=1$ and $\\theta_{y}\\ge0$ for $y\\in\\left\\{ 1,\\ldots,k\\right\\}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression\n",
    "\n",
    "• From each x, we compute a linear score function for each class: \n",
    "\n",
    "$$x\\mapsto\\left(\\left\\langle w_{1},x\\right\\rangle ,\\ldots,\\left\\langle w_{k},x\\right\\rangle \\right)\\in\\mathbb R^{k}$$\n",
    "\n",
    "• We need to map this $\\mathbb R^{k}$ vector into a probability vector $\\theta$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• The __softmax function__ maps scores $s=\\left(s_{1},\\ldots,s_{k}\\right)\\in\\mathbb R^{k}$ to a categorical distribution: \n",
    "\n",
    "$$\\left(s_{1},\\ldots,s_{k}\\right)\\mapsto\\theta=\\textrm {softmax}\\left(s_{1},\\ldots,s_{k}\\right)=\\left(\\frac{\\exp\\left(s_{1}\\right)}{\\sum_{i=1}^{k}\\exp\\left(s_{i}\\right)},\\ldots,\\frac{\\exp\\left(s_{k}\\right)}{\\sum_{i=1}^{k}\\exp\\left(s_{i}\\right)}\\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression: Learning\n",
    "\n",
    "• Let $y\\in\\left\\{ 1,\\ldots,k\\right\\}$  be an index denoting a class.\n",
    "\n",
    "• Then predicted probability for class $y$ given $x$ is \n",
    "\n",
    "$$\\hat{p}(y\\mid x)=\\textrm{softmax}\\left(\\left\\langle w_{1},x\\right\\rangle ,\\ldots,\\left\\langle w_{k},x\\right\\rangle \\right)_{y}$$\n",
    ",where the $y$ subscript indicates taking the $y$'th entry of the vector produced $\\textrm{softmax}$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• __Learning__: Maximize the log-likelihood of training data\n",
    "\n",
    "$$\\textrm{argmax}_{w_{1},\\ldots,w_{k}\\in\\mathbb R^{d}}\\sum_{i=1}^{n}\\log\\left[\\textrm{softmax}\\left(\\left\\langle w_{1},x_{i}\\right\\rangle ,\\ldots,\\left\\langle w_{k},x_{i}\\right\\rangle \\right)_{y_{i}}\\right]$$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• This objective function is concave in $w$'s and straightforward to optimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard MLP for Multiclass\n",
    "\n",
    "### Nonlinear Generalization of Multinomial Logistic Regression\n",
    "\n",
    "Could make each class a separate task / output.\n",
    "\n",
    "• Key change: Rather than k linear score functions\n",
    "\n",
    "$$x\\mapsto\\left(\\left\\langle w_{1},x\\right\\rangle ,\\ldots,\\left\\langle w_{k},x\\right\\rangle \\right)\\in\\mathbb R^{k}$$,\n",
    "\n",
    "use nonlinear score functions:\n",
    "\n",
    "$$x\\mapsto\\left(f_{1}(x),\\ldots,f_{k}(x)\\right)\\in\\mathbb R^{k}$$,\n",
    "\n",
    "• Then predicted probability for class $y\\in\\left\\{ 1,\\ldots,k\\right\\}$  given x is \n",
    "$$\\hat{p}(y\\mid x)=\\textrm {softmax}\\left(f_{1}(x),\\ldots,f_{k}(x)\\right)_{y}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Generalization of Multinomial Logistic Regression\n",
    "\n",
    "• __Learning__: Maximize the log-likelihood of training data\n",
    "\n",
    "$$\\textrm{ argmax}_{f_{1},\\ldots,f_{k}}\\sum_{i=1}^{n}\\log\\left[\\textrm{softmax}\\left(f_{1}(x),\\ldots,f_{k}(x)\\right)_{y_{i}}\\right]$$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• We could use gradient boosting to get $f_{i}$'s as ensembles of regression trees.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Today we'll learn to use a multilayer perceptron for $f:\\mathbb R^{d}\\to\\mathbb R^{k}$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Unfortunately, this objective function will not be concave or convex. \n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• But we can still use gradient methods to find a good local optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Standard Recipe\n",
    "\n",
    "• __Input space__: $\\mathcal X=\\mathbb R^{d}$ __Action space__ $\\mathcal A =\\mathbb R^{k}$ (for k-class classification).\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Let $\\sigma:\\mathbb R\\to\\mathbb R$ be a non-polynomial activation function (e.g. $\\tanh$ or ReLU).\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Let's take all hidden layers to have m units.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• First hidden layer is given by \n",
    "\n",
    "$$h^{(1)}(x)=\\sigma\\left(W^{(1)}x+b^{(1)}\\right),$$ \n",
    "for parameters $W^{(1)}\\in\\mathbb R^{m\\times d}$ and $b\\in\\mathbb R^{m}$, and where $\\sigma\\left(\\cdot\\right)$ is applied to each entry of its argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "Neural networks are a simply a machine learning algorithm with a more complex hypothesis class, directly incorporating non-linearity (in the parameters)\n",
    "\n",
    "__Example__: neural network for logistic regression\n",
    "\n",
    "Frame Linear Prediction Functions\n",
    "\n",
    "• Linear prediction functions: SVM, ridge regression, Lasso\n",
    "\n",
    "• Generate the feature vector $\\phi(x)$ by hand.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Learn parameter vector w from data.\n",
    "\n",
    "\n",
    "<img src=\"neural-networks/linear-classifier.png\" width = 300>\n",
    "\n",
    "• So for $w\\in\\mathbb R^{3}$, $\\text{score}=\\sigma(w^{T}\\phi(x))$ where $\\sigma$ is an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Network (Multilayer Perceptron)\n",
    "\n",
    "• Add an extra layer with hidden nodes $h_{1}$ and $h_{2}$:\n",
    "\n",
    "<img src=\"neural-networks/neural-network-percy.png\" width = 300>\n",
    "\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• For parameter vector $v_{i}\\in\\mathbb R^{3}$, define $h_{i}=\\sigma\\left(v_{i}^{T}\\phi(x)\\right)$,where $\\sigma$ is a nonlinear activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Network (Multilayer Perceptron)\n",
    "\n",
    "\n",
    "<img src=\"neural-networks/neural-network-percy.png\" width = 300>\n",
    "\n",
    "• For parameters $w_{1},w_{2}\\in\\mathbb R$, score is just \n",
    "\n",
    "$\\text{score}\t=\tw_{1}h_{1}+w_{2}h_{2} =\tw_{1}\\sigma(v_{1}^{T}\\phi(x))+w_{2}\\sigma\\left(v_{2}^{T}\\phi(x)\\right)$\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• This is the basic recipe.\n",
    "\n",
    "– We can add more hidden layers. (>1 hidden layer is a “deep network”.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "\n",
    "• The nonlinearity of the activation function is a key ingredient.\n",
    "\n",
    "• The logistic sigmoid function is a classic activation function:$\\sigma(x)=\\frac{1}{1+e^{-x}}$.\n",
    "\n",
    "<img src=\"neural-networks/activationFn-Sigmoid.png\" width = 500>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "\n",
    "\n",
    "• The hyperbolic tangent is a common activation function these days:  $\\sigma(x)=\\tanh\\left(x\\right)$.\n",
    "\n",
    "<img src=\"neural-networks/activationFn-Tanh.png\" width = 500>\n",
    "\n",
    "\n",
    " _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    " \n",
    " • (Shape exactly the same – notice just the axis scales have changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "• More recently, the rectified linear function has been very popular:$\\sigma(x)=\\max(0,x)$.\n",
    "\n",
    "• “ReLU” is much faster to calculate, and to calculate its derivatives.\n",
    "\n",
    "• Also often seems to work better.\n",
    "\n",
    " <img src=\"neural-networks/activationFn-Rectified_Linear.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations Functions\n",
    "$$a^i_j = \\sigma(x^i_j) = \\frac{\\exp(z^i_j)}{\\sum\\limits_k \\exp(z^i_k)}$$\n",
    "\n",
    "\n",
    "<img src=\"softmax.png\" width = 800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [-3, -2, -1, 0, 1, 2, 3]\n",
    "y = [2, 2, 2, 2, 2.9, 2.9, 2.9]\n",
    "plt.plot(np.exp(x) / np.sum(np.exp(x)))\n",
    "plt.grid(True)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('f(x)', fontsize=15)\n",
    "plt.savefig('softmax.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Activation Functions\n",
    "<img src=\"activation_functions.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs of Derivatives Activation Functions\n",
    "<img src=\"derivatives_activation.png\" width = 500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures are often shown graphically\n",
    "\n",
    "<img src=\"./image_files/nn_structure.png\" width = 300>\n",
    "\n",
    "Middle layer $a$ is referred to as the hidden layer, there is nothing in the data that prescribes what values these should take, left up to the algorithm to decide\n",
    "\n",
    "Viewed another way: neural networks are like linear classifiers where the features themselves are also learned\n",
    "\n",
    "__Pros__\n",
    "\n",
    "- No need to manually engineer good features, just let the machine learning algorithm handle this part\n",
    "\n",
    "- It turns out that a 3-layer network is a universal function approximator, any non-linear function can be represented with a 3-layer network with a large enough hidden layer\n",
    "\n",
    "__Cons__\n",
    "\n",
    "- Minimizing loss on training data is no longer a convex optimization problem in parameters $\\theta$\n",
    "\n",
    "- Still need to engineer a good architecture (more on this shortly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__: neural network with one hidden layer\n",
    "\n",
    "$$h_{\\theta}(x) = \\Theta^{(2)} f\\left( \\Theta^{(1)}x\\right)$$\n",
    "\n",
    "where $\\Theta^{(1)} \\in \\mathbb{R}^{k \\times n}, \\Theta^{(2)} \\in \\mathbb{R}^{1 \\times k}$ and $f$ is some non-linear function applied elementwise to a vector (common choice is \"tanh\" function $\\tanh(x) = \\frac{1 - e^{-2x}}{1+e^{-2x}}$)\n",
    "\n",
    "<img src=\"./image_files/tanh.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Regression with Multilayer Perceptrons (MLPs)\n",
    "\n",
    "## MLP Regression \n",
    "\n",
    "• Input space: $\\mathcal X=\\mathbb R$ \n",
    "\n",
    "• Action Space / Output space: $\\mathcal A=\\mathcal Y=\\mathbb R$\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Hypothesis space: MLPs with a single 3-node hidden layer:\n",
    "\n",
    "$f(x)=w_{0}+w_{1}h_{1}(x)+w_{2}h_{2}(x)+w_{3}h_{3}(x)$,\n",
    "\n",
    "where \n",
    "\n",
    "$h_{i}(x)=\\sigma(v_{i}x+b_{i})\\text{ for }i=1,2,3$,\n",
    "\n",
    "for some fixed nonlinear “activation function” $\\sigma:\\mathbb R\\to\\mathbb R$. \n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• What are the parameters we need to fit?\n",
    "\n",
    "$b_{1},b_{2},b_{3},v_{1},v_{2},v_{3},w_{0},w_{1},w_{2},w_{3}\\in\\mathbb R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron for $f:\\mathbb R\\to\\mathbb R$\n",
    "\n",
    "• MLP with one hidden layer; $\\sigma$ typically activation functions $\\tanh$ or $\\text{RELU}$; $x,h_{1},h_{2},h_{3,}\\hat{y}\\in\\mathbb R$.\n",
    "\n",
    "\n",
    "<img src=\"neural-networks/mlp-1d-regression.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer as Feature/Basis Functions\n",
    "\n",
    "• Can think of $h_{i}=h_{i}(x)=\\sigma(v_{i}x+b_{i})$ as a feature of $x$.\n",
    "\n",
    "– Learned by fitting the parameters $v_{i}$ and $b_{i}$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Here are some $h_{i}(x)$'s for $\\sigma=\\tanh$ and randomly chosen $v_{i}$ and $b_{i}$:\n",
    "\n",
    "\n",
    "<img src=\"neural-networks/tanh-hidden-functions.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples from the Hypothesis Space\n",
    "\n",
    "• Choosing 6 sets of random settings for $b_{1},b_{2},b_{3},v_{1},v_{2},v_{3},w_{0},w_{1},w_{2},w_{3}\\in\\mathbb R$, we get the following score functions:\n",
    "\n",
    "<img src=\"Figures/neural-networks/random-NN-scorefns.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose the best hypothesis?\n",
    "\n",
    "• As usual, choose our prediction function using empirical risk minimization.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Our hypothesis space is parameterized by \n",
    "\n",
    "$\\theta=\\left(b_{1},b_{2},b_{3},v_{1},v_{2},v_{3},w_{0},w_{1},w_{2},w_{3}\\right)\\in\\Theta=\\mathbb R^{10}$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• For a training set $(x_{1},y_{1}),\\ldots,(x_{n},y_{n})$, find\n",
    "\n",
    "$$\\hat{\\theta}=\\textrm {argmin}_{\\theta\\in\\mathbb R^{10}}\\frac{1}{n}\\sum_{i=1}^{n}\\left(f_{\\theta}(x_{i})-y_{i}\\right)^{2}$$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Do we have the tools to find $\\hat{\\theta}$?\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Not quite, but close enough..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Methods for MLPs\n",
    "\n",
    "• Note that\n",
    "\n",
    "$$f(x)\t=\tw_{0}+\\sum_{i=1}^{3}w_{i}h_{i}(x) =\tw_{0}+\\sum_{i=1}^{3}w_{i}\\tanh(v_{i}x+b_{i})$$\n",
    "\n",
    "is differentiable w.r.t. all parameters.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• We can use gradient-based methods as usual.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• However, the objective function is not convex w.r.t. parameters.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• So we can only hope to converge to a local minimum.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• In practice, this seems to be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Approximation Ability: $f(x)=x^{2}$\n",
    "\n",
    "• 3 hidden units; tanh activation functions \n",
    "\n",
    "• Blue dots are training points; Dashed lines are hidden unit outputs; Final output in Red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"Figures/neural-networks/Figure5.3a.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20fcc956e80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"neural-networks/Figure5.3a.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation Ability: $f(x)=\\sin(x)$\n",
    "\n",
    "• 3 hidden units; logistic activation function\n",
    "\n",
    "• Blue dots are training points; Dashed lines are hidden unit outputs; Final output in Red.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"Figures/neural-networks/Figure5.3b.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20fcc956a90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"Figures/neural-networks/Figure5.3b.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation Ability: $f(x)=\\left|x\\right|$\n",
    "\n",
    "• 3 hidden units; logistic activation functions \n",
    "\n",
    "• Blue dots are training points; Dashed lines are hidden unit outputs; Final output in Red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"Figures/neural-networks/Figure5.3c.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20fcc9565f8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"Figures/neural-networks/Figure5.3c.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation Ability: $f(x)= 1 {x>0}$\n",
    "\n",
    "• 3 hidden units; logistic activation function\n",
    "\n",
    "• Blue dots are training points; Dashed lines are hidden unit outputs; Final output in Red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"Figures/neural-networks/Figure5.3d.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x20fcc956e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"Figures/neural-networks/Figure5.3d.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Approximation Theorems\n",
    "\n",
    "Leshno and Schocken (1991) showed:\n",
    "\n",
    "– A neural network with one [possibly huge] hidden layer can uniformly approximate any continuous function on a compact set iff the activation function is not a polynomial (i.e. tanh, logistic, and ReLU all work, as do $\\sin$,$\\cos$, $\\exp$, etc.). \n",
    "\n",
    "• In more words:\n",
    "\n",
    "– Let $\\varphi(\\cdot)$ be any non-polynomial function (an activation function).Let K be any compact set in $\\mathbb R^{m}$. (Such as the unit hypercube $[0,1]^{m}$.)\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "– Let $f:K\\to\\mathbb R$ be any continuous function on a compact set $K\\subset\\mathbb R^{m}$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "– Then $\\forall\\epsilon>0$, there exists an integer N (the number of hidden units), and parameters $v_{i},b_{i}\\in\\mathbb R$ and $w_{i}\\in\\mathbb R^{m}$ such that the function $F(x)=\\sum_{i=1}^{N}v_{i}\\varphi(w_{i}^{T}x+b_{i})$ satisfies $\\left|F(x)-f(x)\\right|<\\epsilon$ for all $x\\in K$. \n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Leshno & Schocken note that this doesn't work without the bias $term b_{i}$ (they call it the threshold term). (e.g. consider $\\varphi=\\sin$: then we always have $F(-x)=-F(x))$ Hornik et al and concurrently by Cybenko in 1989 showed we get uniform approximation for activation functions that are nonconstant, bounded, nondecreasing, and continuous. These functions are known as squashing functions.). http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.441.7873&rep=rep1&type=pdf Leshno: https://archive.nyu.edu/bitstream/2451/14384/1/IS-91-26.pdf points out that the bias term (they call the threshold) is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Standard Recipe\n",
    "\n",
    "• __Input space__: $\\mathcal X=\\mathbb R^{d}$  __Action space__: $\\mathcal A=\\mathbb R^{k}$ (for k-class classification).\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Let $\\sigma:\\mathbb R\\to\\mathbb R$ be a non-polynomial activation function (e.g. $\\tanh$ or ReLU).\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Let's take all hidden layers to have $m$ units.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• First hidden layer is given by\n",
    "\n",
    "$$h^{(1)}(x)=\\sigma\\left(W^{(1)}x+b^{(1)}\\right)$$,\n",
    "for parameters $W^{(1)}\\in\\mathbb R^{m\\times d}$ and $b\\in\\mathbb R^{m}$, and where $\\sigma\\left(\\cdot\\right)$ is applied to each entry of its argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Standard Recipe\n",
    "\n",
    "• Each subsequent hidden layer takes the output $o\\in\\mathbb R^{m}$ of previous layer and produces \n",
    "\n",
    "$$h^{(j)}(o)=\\sigma\\left(W^{(j)}o+b^{(j)}\\right),\\text{ for }j=1,\\ldots,D$$\n",
    "\n",
    "where $W^{(j)}\\in\\mathbb R^{m\\times m}$, $b^{(j)}\\in\\mathbb R^{m}$, and $D$ is the number of hidden layers.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Last layer is an affine mapping: \n",
    "\n",
    "$$a(o)=W^{(D+1)}o+b^{(D+1)}$$,\n",
    "where $W^{(D+1)}\\in\\mathbb R^{k\\times m}$ and $b^{(D+1)}\\in\\mathbb R^{k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• So the full neural network function is given by the composition of layers:\n",
    "\n",
    "$$f(x)\t=\t\\left(a\\circ h^{(D)}\\circ\\cdots\\circ h^{(1)}\\right)(x)$$\n",
    "\n",
    "• This gives us the $k$ score functions we need.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• To train this we maximize the conditional log-likelihood for the training data:\n",
    "\n",
    "$$J(\\theta)=\\frac{1}{n}\\sum_{i=1}^{n}\\log\\left[\\textrm{softmax}(f(x_{i}))_{y_{i}}\\right]$$,\n",
    "\n",
    "where $\\theta=(W^{(1)},\\ldots,W^{(D+1)},b^{(1)},\\ldots,b^{(D+1)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gradient of a Hidden Computation Node\n",
    "\n",
    "• For simplicity, consider the a hidden layer with a single node and $\\tanh$ nonlinearity:\n",
    "\n",
    "$$o(x)=\\tanh(w^{T}x+b)$$\n",
    "for parameters $b\\in\\mathbb R$ and $w\\in\\mathbb R^{d}$. We can represent this in a computation graph as\n",
    "\n",
    "\n",
    "<img src=\"Figures/backpropagation/hidden-comp-node.png\" width = 450>\n",
    "\n",
    "\n",
    "\n",
    "• Suppose we can write a first order approximation to $o$ as \n",
    "\n",
    "$$o\\approx g_{w}^{T}w+g_{b}b+c$$,\n",
    "\n",
    "where $c,g_{b}\\in \\mathbb R$ and $g_{w}\\in\\mathbb R^{d}$ may depend on $x$. \n",
    "\n",
    "• Then the we know that $g_{w}$ and $g_{b}$ are the gradients of $o$ w.r.t. $w$ and $b$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification: Cross-Entropy Loss\n",
    "\n",
    "\n",
    "\n",
    "• Network can do better if it “knows” that classes are mutually exclusive.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• Need to introduce a joint loss across the outputs. \n",
    "\n",
    "• Joint loss function (cross-entropy/deviance):\n",
    "\n",
    "$$\\ell(w,v)=-\\sum_{i=1}^{n}\\sum_{i=1}^{K}y_{ik}\\log f_{k}(x_{i})$$,\n",
    "\n",
    "where $y_{ik}=1 ({y_{i}=k})$.\n",
    "\n",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
    "\n",
    "• This is the negative log-likelihood we get for softmax predictions in multinomial logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "\n",
    "\"Deep\" neural networks typically refer to networks with multiple hidden layers\n",
    "\n",
    "<img src=\"./image_files/deep_structure.png\" width = 450>\n",
    "\n",
    "Note: original term \"deep learning\" referred to any machine learning architecture with multiple layers, including several probabilistic models, etc, but most work these days focuses on neural networks\n",
    "\n",
    "Motivation from neurobiology: brain appears to use multiple levels of interconnected neurons to process information (but careful,neurons in brain are not just non-linear functions)\n",
    "\n",
    "In practive: works better for many domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Output Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "• Very easy to add extra outputs to neural network structure.\n",
    "\n",
    "<img src=\"Figures/neural-networks/multiple-output-nn.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks\n",
    "\n",
    "## Optimizing neural network parameters\n",
    "\n",
    "<img src=\"./image_files/nn_structure.png\" width = 300>\n",
    "\n",
    "How do we optimize the parameters for the machine learning loss minimization problem with a neural network\n",
    "\n",
    "$$ \\min_{\\theta} \\sum_{i=1}^{m}\\ell\\left( h_{\\theta}\\left(x^{(i)}\\right),y^{(i)}\\right)$$\n",
    "\n",
    "now is this problem non-convex?\n",
    "\n",
    "Just do exactly what we did before:  initialize with random weights and run stochastic gradient descent\n",
    "\n",
    "Now have the possibility of local optima, and function can be harder to optimize, but we will not worry about all that because the resulting model still often perform better than linear models\n",
    "\n",
    "Stochastic gradient descent, repeat:\n",
    "\n",
    "- Select some example $i$\n",
    "\n",
    "$$ \\theta:= \\theta - \\alpha \\nabla_{\\theta} \\left( h_{\\theta} \\left(x^{(i)}\\right),y^{(i)}\\right)$$\n",
    "\n",
    "So how do we compute the gradient with respect to all the parameters in a neural network (_i.e._, all weights $\\Theta^{(1)}, \\Theta^{(2)}, \\cdots$) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Backpropagation is a method for computing all the necessary gradients using one \"forward pass\" (just computing all the values at layers), and one \"backward pass\" (computing gradients backwards in the network)\n",
    "\n",
    "The equations sometimes look complex, it is just an application of the chain rule of calculus\n",
    "\n",
    "First, some notation that will make things a bit easier:\n",
    "\n",
    "- Activations: $a^{(i)}$ values at hidden layer $i$ (with convention that $a^{(1)} = x$)\n",
    "\n",
    "- Linear activation: $z^{(i)} = \\Theta^{(i)}a^{(i)}$, so $a^{(i+1)} = f(z^{(i)})$\n",
    "\n",
    "Let's treat everything as scalars for now, and consider a network with two hidden layers:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial \\Theta^{(1)}}\\ell \\left( h_{\\theta}(x),y \\right) & = \\frac{\\partial}{\\partial \\Theta^{(1)}}\\ell \\left( \\Theta^{(3)}f(\\Theta^{(2)}f(\\Theta^{(1)}x))   ,y \\right)\\\\\n",
    "& = \\ell'\\left( z^{(3)},y\\right) \\Theta^{(3)} \\frac{\\partial}{\\partial \\Theta^{(1)}} f(\\Theta^{(2)}f(\\Theta^{(1)}x))\\\\\n",
    "& = \\ell'\\left( z^{(3)},y\\right) \\Theta^{(3)} f'\\left(z^{(2)} \\right)\\Theta^{(2)}\\frac{\\partial}{\\partial \\Theta^{(1)}}f(\\Theta^{(1)}x)\\\\\n",
    "& = \\ell'\\left( z^{(3)},y\\right) \\Theta^{(3)} f'\\left(z^{(2)} \\right)\\Theta^{(2)} f'\\left( z^{(1)}\\right) a^{(1)}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "By the same procedure\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\Theta^{(2)}}\\ell \\left( h_{\\theta}(x),y \\right) = \\ell'\\left( z^{(3)},y\\right) \\Theta^{(3)} f'\\left(z^{(2)} \\right) a^{(2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to compute gradients with respect to all the parameters $\\Theta^{(1)},\\cdots,\\Theta^{(L)}$, we can \"reuse\" parts of this computation\n",
    "\n",
    "Let\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "g^{(L)} & = \\ell'\\left( z^{(L)}\\right) \\Theta^{(L)}\\\\\n",
    "g^{(i)} & = g^{(i+1)} f'\\left(z^{(i)} \\right)\\Theta^{(i)}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "then\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial \\Theta^{(i)}}\\ell \\left( h_{\\theta}(x),y \\right) = g^{(i+1)} f'\\left(z^{(i)} \\right) a^{(i)}\n",
    "$$\n",
    "\n",
    "It takes just slightly more advanced calculus, but it turns out the general matrix/vector case is exactly the same, just being carful with the ordering/size of matrix multiplication\n",
    "\n",
    "The full backpropagation algorithm:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "g^{(L)} & = {\\Theta^{(L)}}^T \\ell'\\left( z^{(L)}\\right) \\\\\n",
    "g^{(i)} & = {\\Theta^{(i)}}^T g^{(i+1)} f'\\left(z^{(i)} \\right)\\\\\n",
    "\\nabla_{\\Theta^{(i)}}\\ell \\left( h_{\\theta}(x),y \\right) &= \\left( g^{(i+1)} \\cdot f'\\left(z^{(i)} \\right) \\right) {a^{(i)}}^T\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where $\\cdot$ denotes elementwise multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients can get somewhat tedious to derive by hand, especially for the more complex models \n",
    "\n",
    "__Fortunately, a lot of this work has already been done for us__\n",
    "\n",
    "Tools like Theano, Torch, Caffe, TensorFlow all let us specify the network structure and then automatically compute all gradients (and use GPUs to do so)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/uXt8qF2Zzfo\" \n",
       " width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/uXt8qF2Zzfo\" \n",
    " width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is changed since the 80s?\n",
    "\n",
    "All these algorithms (and most of the extensions in later slides), were developed in the 80s or 90s\n",
    "\n",
    "So why are these just becoming more popular in the last few years?\n",
    "\n",
    "- more data\n",
    "\n",
    "- faster computers\n",
    "\n",
    "- (some) better optimization techniques\n",
    "\n",
    "__Unsupervised pre-training (Hinton et al., 2006)__: \"Pre-train\" the network have the hidden layers recreate their input, one layer at a time, in an unsupervised fashion\n",
    "\n",
    "- This paper was partly responsible for re-igniting the interest in deep neural networks, but the general feeling now is that it does not help much\n",
    "\n",
    "__Dropout (Hinton et al., 2012)__: During training and computation of gradients, randomly set about half the hidden units to zero \n",
    "\n",
    "- Acts like regularization, prevents the parameters for overfitting to particular exampels\n",
    "\n",
    "__Different non-linear fuctions (Nair and Hinton, 2010)__: Use non-linearity $f(x) = \\max\\{0,x\\}$ instead of $f(x) = \\tanh(x)$\n",
    "\n",
    "## Again, why successful?\n",
    "\n",
    "- Pre-training: Restricted Boltzmann machine (RBM), Autoencoder, nonnegative matrix factorization (NMF)\n",
    "\n",
    "- Training: Dropout\n",
    "\n",
    "- Rectified linear units: No vanishing gradient, sparse activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/VrMHA3yX_QI\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/VrMHA3yX_QI\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Advanced Models and Architectures in Deep Learning\n",
    "- Convolutional neural networks\n",
    "\n",
    "- Recurrent neural networks\n",
    "\n",
    "- Deep reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks\n",
    "\n",
    "One of the biggest successes for neural networks has come in computer vision, using convolution neural networks.\n",
    "\n",
    "In traditional neural networks, images are treated as unstructured vectors $x \\in \\mathbb{R}^{W\\cdot H}$, and we learn arbitrary transformation _i.e._, $f(\\Theta x)$\n",
    "\n",
    "But this does not seem like a good model, slightly shifting/scaling image winds up with a very different input vector, so we need to learn all these invariances in our parameters.\n",
    "\n",
    "Basic idea of convolutional neural networks: parameters are elements of a (set of) convolutional filters applied to the image\n",
    "\n",
    "$$ a^{(i+1)} = f\\left( a^{(i)} \\ast \\Theta^{(i)}\\right)$$\n",
    "\n",
    "The function $f$ also does downsampling \"max-pooling\" to produce lower dimensional images and translation invariance at later layers.\n",
    "\n",
    "__ImageNet Large Scale Visual Recognition Challenge (ILSVRC)__\n",
    "\n",
    "- Lenet-5 (LeCun et al., 1998) architecture, 1% error on MNIST classification (compare to 10% for linear classifier)\n",
    "\n",
    "<img src=\"./image_files/Lenet.png\" width = 700>\n",
    "\n",
    "- \"AlexNet\" (Krizhevsky et al., 2012), work ImageNet 2012 competition with a Top-5 error rate of 15.3% (next best system with highly engineered features based upon SIFT got 26.1% error)\n",
    "\n",
    "<img src=\"./image_files/AlexNet.png\" width = 700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/bL1Zymz1b7g\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/bL1Zymz1b7g\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\;\\;$<a href=\"./files/deep_learning_tutorial_2015.pdf\" target=\"_blank\">Slides available</a> (click to open in a new page)\n",
    "\n",
    "- By Phillip Isola\n",
    "\n",
    "- Tutorial Series in Computational topics for BCS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Recurrent neural networks\n",
    "\n",
    "Framework for dealing with _sequence_ data: hidden units for elements in sequence are fed into hidden units for subsequent elements\n",
    "\n",
    "- difference equation\n",
    "\n",
    "- time series analysis\n",
    "\n",
    "- hidden Markov model (HMM)\n",
    "\n",
    "<img src=\"./image_files/RNN.png\" width = 500>\n",
    "<center>Figure from Karpathy, 2015 (http://karpathy.github.io/2015/05/21/rnn-effectiveness/)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep reinforcement learning\n",
    "\n",
    "Instead of maintaining a separate Q-value for each state/action pair, we can use a deep neural network (or any other class of functions) to represent the Q function\n",
    "\n",
    "Q-Learning update rule becomes\n",
    "\n",
    "$$\\theta := \\theta - \\alpha \\left( R+\\gamma \\max_{a'}Q(s',a';\\theta) -Q(s,a;\\theta)\\right) \\nabla_{\\theta} Q(s,a;\\theta) $$\n",
    "\n",
    "where $\\theta$ are the parameters (_i.e._, network weights) that specify our reprentation of the Q function\n",
    "\n",
    "Google DeepMind paper shows deep learning to play Atari video games: Pong, Breakout, Space Invaders, Seaquest, Beam Rider (Mihn et al., 2013)\n",
    "\n",
    "- Markov decision process (MDP)\n",
    "\n",
    "- Bellman equations\n",
    "\n",
    "- Reinforcement learning\n",
    "\n",
    "- Q-learning"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
